{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week6_hw PCA and K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import timedelta, date\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='hsiehkl', api_key='FXXF2GQeCytUbJX9YoB2')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chinese(uchar):         \n",
    "    if u'\\u4e00' <= uchar<=u'\\u9fff':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/bf/kxrhqhkd3s1263kmtf84x8zw0000gn/T/jieba.cache\n",
      "Loading model cost 0.677 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 專有名詞\n",
    "jieba.load_userdict('ProperN.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"大同20170103/\", \"大同20180102/\", \"大同20180709/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txts(folder):\n",
    "    all_files = os.listdir(\"News/\" + folder)   # imagine you're one directory above test dir\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取新聞檔案，並使用jieba切詞\n",
    "def textMining(folder, file):\n",
    "    with open(\"./News/\" + folder + file, 'rt',encoding=\"utf-8\") as txt:\n",
    "        data = txt.read()\n",
    "    #text segmentation\n",
    "    seg_list = jieba.cut(data, cut_all=False)\n",
    "    seg_list = list(seg_list)\n",
    "    filter_list = []\n",
    "    wordDict = {}\n",
    "    jump = False\n",
    "    for word in seg_list:\n",
    "        for s in word:\n",
    "            if not is_chinese(s):\n",
    "                jump = True\n",
    "                break\n",
    "        if not jump:\n",
    "            filter_list.append(word)\n",
    "        jump = False\n",
    "    return filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(folder, corpus, txts_in_folder):\n",
    "    # tfidf\n",
    "    vectorizer = TfidfVectorizer(max_df = 0.9, min_df = 0.2)\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "    words = vectorizer.get_feature_names()\n",
    "    print(\"tfidf.shape: \", tfidf.shape)\n",
    "    for i in range(len(corpus)):\n",
    "        print('----{0} NEWS----'.format(txts_in_folder[i]))\n",
    "        for j in range(len(words)):\n",
    "            if tfidf[i,j] > 0.2:\n",
    "                print(words[j], tfidf[i,j], i ,j)\n",
    "    \n",
    "    X = tfidf.toarray()\n",
    "    len(X)\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    sklearn_pca = sklearnPCA(n_components = 2)\n",
    "    Y_sklearn = sklearn_pca.fit_transform(X_std)\n",
    "    Y_sklearn[:3]\n",
    "    \n",
    "    return Y_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cpa_scatter(Y_sklearn, txts_in_folder):\n",
    "    pca_data = [\n",
    "        go.Scatter(\n",
    "            x = Y_sklearn[:,0],\n",
    "            y = Y_sklearn[:,1],\n",
    "            mode = \"markers\",\n",
    "            hoverinfo = 'text',\n",
    "            text = txts_in_folder\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure(data = pca_data)\n",
    "    return py.iplot(fig, filename = 'PCA Scatter Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans_scatter(Y_sklearn, txts_in_folder):\n",
    "    kmeans = KMeans(n_clusters = 3)\n",
    "    X_clustered = kmeans.fit_predict(Y_sklearn)\n",
    "    \n",
    "    #Define our own color map\n",
    "    LABEL_COLOR_MAP = {0:'red', 1: 'green', 2: 'blue'}\n",
    "    label_color = [LABEL_COLOR_MAP[l] for l in X_clustered]\n",
    "    \n",
    "    pca_data = [\n",
    "        go.Scatter(\n",
    "            x = Y_sklearn[:,0],\n",
    "            y = Y_sklearn[:,1],\n",
    "            mode = \"markers\",\n",
    "            hoverinfo = 'text',\n",
    "            text = txts_in_folder,\n",
    "            marker = dict(color = label_color)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure(data = pca_data)\n",
    "    return py.iplot(fig, filename = 'K-means Scatter Chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  分析大同20180102資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf.shape:  (20, 185)\n",
      "----大同今年展望_180226_經濟日報.txt NEWS----\n",
      "今年 0.23048478393688057 0 12\n",
      "去年 0.3250049774609603 0 26\n",
      "太陽能 0.5712232323965375 0 48\n",
      "資金 0.4284174242974031 0 161\n",
      "郭文艷 0.29837078787496224 0 178\n",
      "----大同換董座_180203_經濟日報.txt NEWS----\n",
      "人士 0.2298169535210584 1 11\n",
      "今年 0.20046889587003497 1 12\n",
      "出現 0.24841659552937362 1 24\n",
      "市場 0.28675871713329565 1 58\n",
      "每股 0.3726248932940604 1 95\n",
      "營運 0.24841659552937362 1 101\n",
      "經營權 0.21409118027436747 1 127\n",
      "股價 0.266557160732481 1 132\n",
      "----大同現增價14元_180110_工商時報.txt NEWS----\n",
      "價格 0.446099750441074 2 16\n",
      "媒體 0.26999743383160724 2 50\n",
      "林宏信 0.33457481283080553 2 87\n",
      "每股 0.33457481283080553 2 95\n",
      "發行 0.3095242652601372 2 112\n",
      "虧損 0.24028694089586644 2 145\n",
      "----大同現增價格市場派質疑_180104_udn新聞網.txt NEWS----\n",
      "價格 0.40303754064179687 3 16\n",
      "公司 0.4775666375198697 3 20\n",
      "增資 0.20151877032089843 3 44\n",
      "每股 0.20151877032089843 3 95\n",
      "為何 0.20151877032089843 3 100\n",
      "發行 0.27964574854852614 3 112\n",
      "股東 0.31578187403186836 3 134\n",
      "----大同現增股東不滿_180107_鉅亨網.txt NEWS----\n",
      "公司 0.22445079051831848 4 20\n",
      "去年 0.2566064208412195 4 26\n",
      "投資 0.21837404187390003 4 67\n",
      "林宏信 0.20295319056430655 4 87\n",
      "欣同 0.20295319056430655 4 93\n",
      "股東 0.5123810617127251 4 134\n",
      "----大同首位女董座_180202_udn新聞網.txt NEWS----\n",
      "太陽能 0.4217174693137526 5 48\n",
      "市場 0.29208473830520476 5 58\n",
      "董事 0.2517351000671531 5 141\n",
      "蔚山 0.22027845935445237 5 143\n",
      "----市場派有8成把握拿下大同_180131_壹週刊.txt NEWS----\n",
      "人士 0.32252485096164385 6 11\n",
      "市場 0.3353640476633131 6 58\n",
      "持股 0.21501656730776258 6 71\n",
      "現增 0.21501656730776258 6 106\n",
      "目前 0.34862756738339873 6 114\n",
      "記者 0.20030354579234205 6 153\n",
      "----市場派農曆年後奇襲_180131_壹週刊.txt NEWS----\n",
      "去年 0.2365564357070744 7 26\n",
      "召開 0.2365564357070744 7 29\n",
      "市場 0.48851001305114866 7 58\n",
      "林家 0.41211203652611417 7 88\n",
      "股東 0.37229247898320533 7 134\n",
      "臨時會 0.20276265917749237 7 139\n",
      "董事 0.243751593433698 7 141\n",
      "----提前改選_180109_自由時報.txt NEWS----\n",
      "公司 0.20766113253328722 8 20\n",
      "去年 0.26590078575996 8 26\n",
      "土地 0.35050703113499665 8 39\n",
      "市場 0.2023032043819049 8 58\n",
      "持股 0.486395391045629 8 71\n",
      "股東 0.2288533035427727 8 134\n",
      "股票 0.3242635940304193 8 136\n",
      "----林家涉掏空尚化_180201_工商時報.txt NEWS----\n",
      "專利 0.3430515133475389 9 54\n",
      "尚化 0.5117827435888632 9 55\n",
      "授權 0.32122368618451436 9 73\n",
      "終止 0.22745899715060588 9 125\n",
      "製造 0.22745899715060588 9 148\n",
      "----林蔚山挨告背信_180201_自由時報.txt NEWS----\n",
      "合作 0.23178448148611366 10 32\n",
      "專利 0.3708551703777818 10 54\n",
      "尚志 0.21823714214424572 10 56\n",
      "授權 0.34725824033503516 10 73\n",
      "精密化 0.26044368025127634 10 124\n",
      "過程 0.2689466782962814 10 172\n",
      "----林蔚山背信掏空_180201_中國時報.txt NEWS----\n",
      "公司 0.3044726926149017 11 20\n",
      "反對 0.2377175940124501 11 27\n",
      "尚化 0.3854349809527579 11 55\n",
      "董事 0.25564117253249496 11 141\n",
      "蔚山 0.20132678858133668 11 143\n",
      "----林蔚山辭大同董事長_180201_鉅亨網.txt NEWS----\n",
      "強調 0.21601229828047847 12 60\n",
      "成為 0.23187918460854678 12 63\n",
      "投入 0.21601229828047847 12 66\n",
      "擔任 0.25064572796760237 12 79\n",
      "產業 0.21601229828047847 12 110\n",
      "社會 0.25064572796760237 12 119\n",
      "董事 0.2078021292641581 12 141\n",
      "董事長 0.3491238175190173 12 142\n",
      "蔚山 0.3491238175190173 12 143\n",
      "辭任 0.2696903682199985 12 166\n",
      "----林蔚山辭大同董座_180202_自由時報.txt NEWS----\n",
      "問題 0.20705256687933704 13 37\n",
      "投資 0.33417734737814064 13 67\n",
      "接任 0.20705256687933704 13 75\n",
      "會中 0.20705256687933704 13 84\n",
      "職務 0.20705256687933704 13 131\n",
      "董事 0.205992567833578 13 141\n",
      "董事長 0.32445338708721394 13 142\n",
      "蔚山 0.2163022580581426 13 143\n",
      "辭任 0.33417734737814064 13 166\n",
      "銀行 0.2873249472575872 13 181\n",
      "----林蔚山閃辭_180202_蘋果日報.txt NEWS----\n",
      "股東 0.27153669235708006 14 134\n",
      "董事長 0.40730503853562006 14 142\n",
      "蔚山 0.5430733847141601 14 143\n",
      "----林郭文艷掌大同 戰市場派_180202_經濟日報.txt NEWS----\n",
      "億元 0.21129132008880214 15 17\n",
      "可能 0.24742258374927675 15 30\n",
      "土地 0.329896778332369 15 39\n",
      "市場 0.3332131641486287 15 58\n",
      "蔚山 0.3015550193872251 15 143\n",
      "資產 0.35539086313547524 15 160\n",
      "通達案 0.24742258374927675 15 170\n",
      "銀行 0.3051964882265373 15 181\n",
      "----涉違反證交法_180131_壹週刊.txt NEWS----\n",
      "專利 0.2032047770322873 16 54\n",
      "尚化 0.4715695325792925 16 55\n",
      "申請 0.2181309044989064 16 111\n",
      "精密化 0.3805503546196901 16 124\n",
      "----董座背信_180201_經濟日報.txt NEWS----\n",
      "委任 0.21749128273751497 17 49\n",
      "尚志 0.44120898133600106 17 56\n",
      "律師 0.2811585433016389 17 61\n",
      "申請 0.20120710498269698 17 111\n",
      "精密化 0.5265377365650893 17 124\n",
      "----質疑林蔚山涉嫌背信_180131_自由時報.txt NEWS----\n",
      "尚化 0.41831669673522115 18 55\n",
      "授權 0.2813133523406726 18 73\n",
      "終止 0.27887779782348077 18 125\n",
      "製造 0.27887779782348077 18 148\n",
      "----違法陸資_180108_udn新聞網.txt NEWS----\n",
      "億元 0.2639339008070643 19 17\n",
      "林宏信 0.34340795263285123 19 87\n",
      "股利 0.274726362106281 19 133\n",
      "股東 0.3228741620460441 19 134\n",
      "資金 0.274726362106281 19 161\n"
     ]
    }
   ],
   "source": [
    "# get corpus from folder 大同20180102\n",
    "txts_in_folder1 = get_txts(folders[1])\n",
    "corpus1 = []\n",
    "\n",
    "for file_name in txts_in_folder1:\n",
    "    filter_list = textMining(folders[1], file_name)\n",
    "    join_list = \" \".join(filter_list)\n",
    "    corpus1.append(join_list)\n",
    "\n",
    "Y_sklearn1 = analyze(folders[1], corpus1, txts_in_folder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hsiehkl/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_cpa_scatter(Y_sklearn1, txts_in_folder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hsiehkl/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_kmeans_scatter(Y_sklearn1, txts_in_folder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析大同20180709資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa6 in position 4: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e6c62700cf65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxts_in_folder2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfilter_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextMining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mjoin_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcorpus2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-53666494974d>\u001b[0m in \u001b[0;36mtextMining\u001b[0;34m(folder, file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtextMining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./News/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#text segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mseg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa6 in position 4: invalid start byte"
     ]
    }
   ],
   "source": [
    "# get corpus from folder 大同20180102\n",
    "txts_in_folder2 = get_txts(folders[2])\n",
    "corpus2 = []\n",
    "\n",
    "for file_name in txts_in_folder2:\n",
    "    filter_list = textMining(folders[2], file_name)\n",
    "    join_list = \" \".join(filter_list)\n",
    "    corpus2.append(join_list)\n",
    "\n",
    "Y_sklearn2 = analyze(folders[2], corpus1, txts_in_folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpa_scatter(Y_sklearn2, txts_in_folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kmeans_scatter(Y_sklearn2, txts_in_folder2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
